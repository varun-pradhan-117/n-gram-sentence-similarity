{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngram-sentence-class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8INdLNW5B9jA",
        "outputId": "0ffc7153-d556-4e9e-da73-471b7a40bfea"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf \n",
        "nltk.download('punkt')\n",
        "\n",
        "class similarityChecker():\n",
        "\n",
        "    # init dunder to load model  \n",
        "    def __init__(self,url):\n",
        "        self.url= url\n",
        "        self.model = hub.load(self.url)\n",
        "        self.sentence_list=[]\n",
        "\n",
        "    # Function to generate a list of unigrams, bigrams and trigrams of given sentence\n",
        "    def generate_ngrams(self,sentence):\n",
        "        ngram_list=[]\n",
        "        for i in range(1,4): \n",
        "            grams=tf.strings.ngrams(sentence,i)\n",
        "            ngram_list.append(grams)\n",
        "        return ngram_list\n",
        "    \n",
        "    # Function to take a list of sentences as input and store their tokens, lengths, ngrams and embeddings\n",
        "    def set_sentences(self,sentence_list):\n",
        "        self.sentence_list=sentence_list\n",
        "        self.cleaned_list=[self.clean_sentence(sentence) for sentence in sentence_list]\n",
        "        self.sentence_lens=[len(sentence) for sentence in self.cleaned_list]\n",
        "        self.ngram_list=[self.generate_ngrams(tokenized_sentence) for tokenized_sentence in self.cleaned_list]\n",
        "        self.embedded_sentences=[self.embed_ngrams(grams) for grams in self.ngram_list]\n",
        "\n",
        "    # Function to get embeddings for given unigrams, bigrams and trigrams and return as list\n",
        "    def embed_ngrams(self,ngram_list):\n",
        "        emb_ngrams=[]\n",
        "        #emb_ngrams=np.arr\n",
        "        for grams in ngram_list:\n",
        "            embedded_grams=np.array(self.model(grams))\n",
        "            emb_ngrams.append(embedded_grams)\n",
        "        return emb_ngrams\n",
        "\n",
        "    # Function to clean a sentence and return as tokens\n",
        "    def clean_sentence(self,sentence):\n",
        "        sentence=re.sub(r\"[^a-zA-Z']\", ' ', sentence)\n",
        "        sentence=re.sub(r\"[^a-zA-Z ]\", '', sentence)\n",
        "        return word_tokenize(sentence)\n",
        "\n",
        "    # Function to get similarity score for given n-gram samples\n",
        "      ## Since USE returns normalized vectors, the cosine similarity can be calculated through the dot product of two vectors  \n",
        "      ## The dot product is calculated by matrix multiplication of sentence 1 n-grams with the transpose of sentence 2 n-grams  \n",
        "      ## Max of all values is taken on the horizontal axis to get the maximum similarity for each n-gram  \n",
        "      ## Score is calculated by getting the sum of similarities and dividing by number of n-grams in sentence 1\n",
        "    def get_score(self,emb1,emb2):\n",
        "        # Get number of ngrams in sentence 1\n",
        "        N1=len(emb1)\n",
        "        ## Get cosine similarity between n-grams\n",
        "        ## This is done by getting dot product of n-grams of sentence 1 with n-grams of sentence 2\n",
        "        sim_matrix=np.matmul(emb1,emb2.T)\n",
        "\n",
        "        ## Get maximum similarity score as match\n",
        "        max_sim=np.max(sim_matrix,axis=1)\n",
        "\n",
        "        ## Get score by dividing sum by number of n-grams in sentence 1\n",
        "        score=np.sum(max_sim)/N1\n",
        "        return score\n",
        "\n",
        "    # Function to calculate similarity score for 2 embedded sentences\n",
        "    def get_sim_score(self,embeds1,embeds2):\n",
        "        final_score=0\n",
        "        # Score has to be divided by sum of length of n-grams i.e. 1+2+3\n",
        "        div=6\n",
        "        for i in range(0,3):\n",
        "          scoren=self.get_score(embeds1[i],embeds2[i])\n",
        "          print(f'{i+1}-gram score: {scoren}')\n",
        "          # Multiply scoren with weight and add to final score\n",
        "          final_score+=(i+1)*scoren\n",
        "        return final_score/div\n",
        "\n",
        "    # Function to find the stored sentence that is most similar to input\n",
        "    def best_sim(self,sentence):\n",
        "        best_sim=0\n",
        "        cleaned_input=self.clean_sentence(sentence)\n",
        "        input_ngrams=self.generate_ngrams(cleaned_input)\n",
        "        input_emb_ngrams=self.embed_ngrams(input_ngrams)\n",
        "        input_len=len(cleaned_input)\n",
        "        score_list=[]\n",
        "        for i in range(0,len(self.sentence_list)):\n",
        "          print(f'Comparing with : {self.sentence_list[i]}')\n",
        "          if input_len>self.sentence_lens[i]:\n",
        "            score=self.get_sim_score(input_emb_ngrams,self.embedded_sentences[i])\n",
        "          else:\n",
        "            score=self.get_sim_score(self.embedded_sentences[i],input_emb_ngrams)\n",
        "          print(\"Final score = \",score)\n",
        "          print('-----------------------')\n",
        "          score_list.append(score)\n",
        "            # Select highest similarity score\n",
        "        best_score=max(score_list)\n",
        "        # Get sentence with highest similarity\n",
        "        best_sentence=self.sentence_list[score_list.index(best_score)]\n",
        "        return best_sentence,best_score"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri4HwR2kCBu0"
      },
      "source": [
        "checker=similarityChecker(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptd0CLd3Iqy7"
      },
      "source": [
        "sentences=[\"Cancel my order\",\n",
        "           \"Show recent items\",\n",
        "           \"Show my orders\",\n",
        "           \"Track my order\",\n",
        "           \"Confirm my order\"]\n",
        "checker.set_sentences(sentences)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybntgENCL8LU",
        "outputId": "7888a686-4733-4565-c914-c4abee2aa59c"
      },
      "source": [
        "checker.best_sim(\"I don't want my package\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing with : Cancel my order\n",
            "1-gram score: 0.5626727104187011\n",
            "2-gram score: 0.43262115120887756\n",
            "3-gram score: 0.30491383870442706\n",
            "Final score =  0.3904427548249563\n",
            "-----------------------\n",
            "Comparing with : Show recent items\n",
            "1-gram score: 0.36089038848876953\n",
            "2-gram score: 0.14835841953754425\n",
            "3-gram score: 0.05635423461596171\n",
            "Final score =  0.13777832190195718\n",
            "-----------------------\n",
            "Comparing with : Show my orders\n",
            "1-gram score: 0.5521993637084961\n",
            "2-gram score: 0.39841723442077637\n",
            "3-gram score: 0.21370967229207358\n",
            "Final score =  0.3316938082377116\n",
            "-----------------------\n",
            "Comparing with : Track my order\n",
            "1-gram score: 0.5742344379425048\n",
            "2-gram score: 0.3852464556694031\n",
            "3-gram score: 0.24673978487650552\n",
            "Final score =  0.3474911173184713\n",
            "-----------------------\n",
            "Comparing with : Confirm my order\n",
            "1-gram score: 0.5626727104187011\n",
            "2-gram score: 0.3768531382083893\n",
            "3-gram score: 0.1868083675702413\n",
            "Final score =  0.31280068159103397\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Cancel my order', 0.3904427548249563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb5SCVq5J5r1",
        "outputId": "90534f44-f72a-41b3-c337-6808bd57eff2"
      },
      "source": [
        "checker.best_sim('Find my package')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing with : Cancel my order\n",
            "1-gram score: 0.5543013413747152\n",
            "2-gram score: 0.5327193737030029\n",
            "3-gram score: 0.3417583107948303\n",
            "Final score =  0.4408358368608687\n",
            "-----------------------\n",
            "Comparing with : Show recent items\n",
            "1-gram score: 0.4209263324737549\n",
            "2-gram score: 0.21649831533432007\n",
            "3-gram score: 0.1797013282775879\n",
            "Final score =  0.23217115799585977\n",
            "-----------------------\n",
            "Comparing with : Show my orders\n",
            "1-gram score: 0.6375230948130289\n",
            "2-gram score: 0.6075990200042725\n",
            "3-gram score: 0.4083702564239502\n",
            "Final score =  0.5129719840155708\n",
            "-----------------------\n",
            "Comparing with : Track my order\n",
            "1-gram score: 0.6176145871480306\n",
            "2-gram score: 0.6145361661911011\n",
            "3-gram score: 0.5404067039489746\n",
            "Final score =  0.5779845052295262\n",
            "-----------------------\n",
            "Comparing with : Confirm my order\n",
            "1-gram score: 0.5649413267771403\n",
            "2-gram score: 0.5035541653633118\n",
            "3-gram score: 0.2844642400741577\n",
            "Final score =  0.40424039628770614\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Track my order', 0.5779845052295262)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1IMSl2BJ_oL",
        "outputId": "c2029991-7378-4e96-eb5a-d61d69d12ebf"
      },
      "source": [
        "checker.set_sentences([\"I hope you have read my mail\"])\n",
        "checker.best_sim(\"I hope you received my mail\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing with : I hope you have read my mail\n",
            "1-gram score: 0.8474416732788086\n",
            "2-gram score: 0.7590710322062174\n",
            "3-gram score: 0.675020408630371\n",
            "Final score =  0.7317741605970594\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I hope you have read my mail', 0.7317741605970594)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}